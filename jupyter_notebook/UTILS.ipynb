{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transpose / Pivot table Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df.set_index('Material Name', inplace=True)\n",
    "\n",
    "trans = df.transpose()\n",
    "\n",
    "trans.reset_index(inplace=True)\n",
    "\n",
    "trans = trans[cols]\n",
    "\n",
    "# One way to do it, for now it can not remain same order easily.\n",
    "trans.melt(id_vars=[\"index\"], ignore_index = False).to_excel('../output/hope.xlsx')\n",
    "\n",
    "# Another way but preverse order.\n",
    "result= trans.set_index([\"index\"]).stack()\n",
    "# Or\n",
    "result = df.pivot(index=[\"some cols\"], columns=\"cols contain values to set name of columns\", values=\"cols that want to get values from\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['columns name'] = pd.to_datetime(df['columns name']], format=\"%d/%m/%Y\", yearfirst=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe to SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "df = pd.read_excel('Byun/take_in.xlsx', header=10)\n",
    "\n",
    "sql_engine = create_engine(\n",
    "        'mysql+pymysql://admin:password@ip/scheme', pool_recycle=3600\n",
    "    )\n",
    "take_in.to_sql('table', sql_engine,\n",
    "              if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walk through files in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import walk\n",
    "\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 40)\n",
    "path = '../data/bom'\n",
    "file_names = next(walk(path), (None, None, []))[2]\n",
    "file_names = (f'{path}/{x}' for x in file_names)\n",
    "dfs = [pd.read_excel(x, header=0, usecols=['Unnamed: 0', 'Plant', 'Entry Date', 'Material', 'Location',\n",
    "       'Stock Type', 'Movement Type', 'Posting Date', 'Unit', 'Quantity',\n",
    "       'Material Document No', 'Provide', 'Reference', 'Unnamed: 13',\n",
    "       'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Previous Stock',\n",
    "       'Entry User']) for x in file_names]\n",
    "def loc_df(df):\n",
    "    lst = [x[0] for x in df['Movement Type'].str.split()]\n",
    "    df['movement type check'] = lst\n",
    "    df = df.loc[df['movement type check'].isin(['101','102','103'])]\n",
    "    return df\n",
    "\n",
    "dfs = [loc_df(df) for df in dfs]\n",
    "\n",
    "result = pd.concat(dfs)\n",
    "result.columns\n",
    "result = result[['Material', 'Unit', 'Movement Type', 'Quantity', 'Reference']]\n",
    "end = result.pivot_table(index=['Material', 'Unit'], columns=['Reference'], aggfunc=np.sum)\n",
    "end.to_excel('../output/GIANGALO.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat all sheets in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "dfs = pd.read_excel('../data/huy_data/TK 1571-2021 NGUYET GOI CHI THUY (1).xlsx', sheet_name=None, header=5,\n",
    "    #    usecols=['TT', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4', 'USD',\n",
    "    #    'Số lượng', 'Số lượng.1', 'Số lượng.2', 'Số lượng.3']\n",
    ")\n",
    "# for name, df in dfs.items():\n",
    "#     print(df.columns)\n",
    "\n",
    "# def loc_df(df):\n",
    "#     df = df.loc[~(pd.isna(df['Unnamed: 3']))]\n",
    "#     return df\n",
    "dfs = list(dfs.values())\n",
    "# dfs = [loc_df(df) for df in dfs]\n",
    "result = pd.concat(dfs)\n",
    "result.to_excel('../output/TK 1571-2021 NGUYET GOI CHI THUY.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat BOM in folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import walk\n",
    "\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 40)\n",
    "path = '../data/huy_data/HĐ 2021'\n",
    "file_names = next(walk(path), (None, None, []))[2]\n",
    "file_names = (f'{path}/{x}' for x in file_names)\n",
    "\n",
    "dfs = [pd.read_excel(x, header=10\n",
    "       ) for x in file_names]\n",
    "# for x in dfs:\n",
    "#     print(x.columns)\n",
    "\n",
    "def loc_df(df):\n",
    "    df = df.loc[~pd.isna(df['(5)'])]\n",
    "    return df\n",
    "\n",
    "dfs = [loc_df(df) for df in dfs]\n",
    "result = pd.concat(dfs)\n",
    "result.ffill(inplace=True)\n",
    "# result.to_excel('../output/HĐ 2021.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.set_index(['(1)','(2)', '(3)','(4)']).stack().to_excel('../output/HĐ 2021.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import walk\n",
    "\n",
    "pd.set_option('display.max_columns', 30)\n",
    "pd.set_option('display.max_rows', 40)\n",
    "path = '../data/GIANG'\n",
    "file_names = next(walk(path), (None, None, []))[2]\n",
    "file_names = (f'{path}/{x}' for x in file_names)\n",
    "dfs = [pd.read_excel(x, header=1, \n",
    "            # usecols=['Unnamed: 0', 'Plant', 'Entry Date', 'Material', 'Location',\n",
    "            # 'Stock Type', 'Movement Type', 'Posting Date', 'Unit', 'Quantity',\n",
    "            # 'Material Document No', 'Provide', 'Reference', 'Unnamed: 13',\n",
    "            # 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Previous Stock',\n",
    "            # 'Entry User']\n",
    "            ) \n",
    "            for x in file_names\n",
    "       ]\n",
    "# def loc_df(df):\n",
    "#     lst = [x[0] for x in df['Movement Type'].str.split()]\n",
    "#     df['movement type check'] = lst\n",
    "#     df = df.loc[df['movement type check'].isin(['101','102','103'])]\n",
    "#     return df\n",
    "\n",
    "# dfs = [loc_df(df) for df in dfs]\n",
    "\n",
    "result = pd.concat(dfs)\n",
    "result.to_excel('../output/GIANGALO.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "\n",
    "\n",
    "# df = pd.read_excel('../data/COSTING BOM T1-12.xlsx', header=5)\n",
    "\n",
    "dfs = pd.read_excel('../data/COSTING BOM T1-12.xlsx', sheet_name=None, header=5,)\n",
    "\n",
    "def loc_df(df):\n",
    "    columns = df.columns\n",
    "    columns = [column for column in columns if not str(column).startswith('Unnamed')]\n",
    "    df = df[columns]\n",
    "    df = df.loc[~pd.isna(df['Mã']) & ~(df['Mã'] == 'Đơn giá NVL') & ~(df['Mã'] == 0)]\n",
    "    result= df.set_index([\"Mã\"]).stack()\n",
    "\n",
    "    result = pd.DataFrame(result)\n",
    "    result.reset_index(inplace=True)\n",
    "    result = result.drop(result[result[0] == 0].index)\n",
    "    return result\n",
    "\n",
    "dfs = [loc_df(df) for df in dfs.values()]\n",
    "\n",
    "result = pd.concat(dfs)\n",
    "\n",
    "with ExcelWriter('../output/end.xlsx') as writer:\n",
    "    for n, df in enumerate(dfs, start=1):\n",
    "        df.rename(columns={\n",
    "            'Mã': 'TP',\n",
    "            'level_1': 'NVL',\n",
    "            0: 'VALUE'\n",
    "        }, inplace=True)\n",
    "        df.to_excel(writer,'sheet %s' % n, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GIANG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('../data/BOM INZI.xlsb')\n",
    "\n",
    "df = df.loc[~pd.isna(df['Semi']) & ~pd.isna(df['Technical BOM'])]\n",
    "df = df[['Level.', 'Product', 'Semi', 'RM', 'Name', 'Unit','Technical BOM']]\n",
    "df['Level.'] = [x.split('.')[-1] for x in df['Level.']]\n",
    "df['Level.'] = df['Level.'].astype(int)\n",
    "\n",
    "# rats = []\n",
    "# previous_level = 1\n",
    "# ratio = [1] * (len(df['Level.'].unique()) + 1)\n",
    "\n",
    "# for row in zip(df['Level.'], df['Technical BOM']):\n",
    "#     if row[0] > 1:\n",
    "#         if row[0] > previous_level:\n",
    "#             ratio[row[0]] = ratio[row[0] - 1] * previous_ratio\n",
    "    \n",
    "#     rats.append(ratio[row[0]])\n",
    "\n",
    "#     previous_ratio = row[1]\n",
    "#     previous_level = row[0]\n",
    "\n",
    "# df['ratio'] = rats\n",
    "# df['BOM'] = df['Technical BOM'] * df['ratio']\n",
    "\n",
    "\n",
    "\n",
    "indexs = []\n",
    "current_level = 1\n",
    "for count, x in enumerate(df['Level.'], start=-1):\n",
    "    if x > current_level:\n",
    "        indexs.append(count)\n",
    "    current_level = x\n",
    "\n",
    "df = df.drop(df.index[indexs])\n",
    "\n",
    "df.to_excel('../output/ENDING.xlsx')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('../data/BCQT2021.BOM.xlsx', header=9)\n",
    "df = df.groupby(['Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3', 'Mã', 'Tên',\n",
    "       'Đơn vị tính']).sum()\n",
    "df.to_excel('../output/bcqt.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93352\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('../data/(03.04.2022)_MEGAELEC_16 FORM_PROCESSING.xlsb', header=10)\n",
    "df = df.groupby(['(1)', '(2)', '(3)', '(4)', '(5)', '(6)', '(7)']).sum()\n",
    "df.reset_index().to_excel('../output/GIANGx.xlsx')\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Thinh\\AppData\\Local\\Temp/ipykernel_4416/2036417805.py:50: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  df = Insert_row(count + k, df, pd.Series())\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def Insert_row(row_number, df, row_value):\n",
    "    # Starting value of upper half\n",
    "    start_upper = 0\n",
    "  \n",
    "    # End value of upper half\n",
    "    end_upper = row_number\n",
    "  \n",
    "    # Start value of lower half\n",
    "    start_lower = row_number\n",
    "  \n",
    "    # End value of lower half\n",
    "    end_lower = df.shape[0]\n",
    "  \n",
    "    # Create a list of upper_half index\n",
    "    upper_half = [*range(start_upper, end_upper, 1)]\n",
    "  \n",
    "    # Create a list of lower_half index\n",
    "    lower_half = [*range(start_lower, end_lower, 1)]\n",
    "  \n",
    "    # Increment the value of lower half by 1\n",
    "    lower_half = [x.__add__(1) for x in lower_half]\n",
    "  \n",
    "    # Combine the two lists\n",
    "    index_ = upper_half + lower_half\n",
    "  \n",
    "    # Update the index of the dataframe\n",
    "    df.index = index_\n",
    "  \n",
    "    # Insert a row at the end\n",
    "    df.loc[row_number] = row_value\n",
    "   \n",
    "    # Sort the index labels\n",
    "    df = df.sort_index()\n",
    "  \n",
    "    # return the dataframe\n",
    "    return df\n",
    "  \n",
    "\n",
    "\n",
    "df = pd.read_excel('../data/(01.04.2022)_MEGAELEC_16 FORM_PROCESSING copy (1).xlsb', header=11)\n",
    "k = 0\n",
    "\n",
    "df = df.loc[df['(5)'] != 'EX-04-00017']\n",
    "current = '00-000-2276-REV-E-MG'\n",
    "for count, x in enumerate(df['(2)']):\n",
    "    if x != current:\n",
    "        for _ in range(11):\n",
    "            df = Insert_row(count + k, df, pd.Series())\n",
    "        k += 11\n",
    "    current = x\n",
    "    \n",
    "\n",
    "df.to_excel('../output/aaaaa.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07848780a58b79594e764c069cbda879259c8dd4f8d3e2f88df491e961ef6dc8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
